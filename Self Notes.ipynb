{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13498fbe-c095-4151-98ef-470f5a60f167",
   "metadata": {},
   "source": [
    "## How to learn anything "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150ae53-2456-4f32-a62c-84fb08c3263b",
   "metadata": {},
   "source": [
    "- Have an overview by watching resources on youtube, that how the work is gonna be.\n",
    "- Just go through all of it, in one go... don't stop to look over anything, understanding not understanding all is fine.\n",
    "- Take your time, and then rego through the material slowly, take notes on the side.\n",
    "- Give your best to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2c847-fb3d-4788-be1b-9cb2031b127b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a232b1ac-8680-415d-9fd0-ddda8e5d9e2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "- [Basics of AWS](https://www.youtube.com/watch?v=gz3dr6o5gxI&list=PLlfy9GnSVerRwvzoRKor9txxfPq9c8FWE)\n",
    "- [AWS Cloud Learning](https://d1.awsstatic.com/training-and-certification/ramp-up_guides/Ramp-Up_Guide_Machine_Learning.pdf) or use [Local pdf](\"http://localhost:8888/lab/tree/Projects/Learning%20AWS/Ramp-Up_Guide_Machine_Learning.pdf\")\n",
    "- [AWS ML](https://explore.skillbuilder.aws/learn/lp/28/Machine%2520Learning%2520Learning%2520Plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee38b2d-4b0d-4079-ab7d-c0d24e69fdcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00211372-4d5b-4ddf-9215-4a187a02d971",
   "metadata": {},
   "source": [
    "[Definitions](https://iqss.github.io/dss-workshops/PythonWebScrape.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6732d6-43f0-46a2-adb1-abc87cb5d874",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554c5e8-e31a-4ba8-b8ef-7e85bc42cd47",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Important Viz codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e29e55-c78c-408e-8a51-9ad570971988",
   "metadata": {},
   "source": [
    "- Visualize Null Values in a dataset\n",
    "``` python\n",
    "sns.heatmap(viddf.isnull(),yticklabels = False, cbar = False, cmap = 'viridis')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- To find the actual name of parameter to be set\n",
    "``` python\n",
    "import matplotlib\n",
    "for i in matplotlib.rc_params():\n",
    "    if 'rotation' in i:\n",
    "        print(i)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28dbab-521a-4b90-93aa-d65121cefc89",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Getting Colors for the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7191fd-64fc-4a19-8a81-bd8185f2cf49",
   "metadata": {
    "tags": []
   },
   "source": [
    "``` python\n",
    "colors = plt.cm.tab10.colors[:10]\n",
    "#colors = sns.color_palette('Set1', 10)\n",
    "channel_colors = {}\n",
    "chdd.sort_values('subscribers',ascending=False,inplace=True)\n",
    "for i, channel in enumerate(chdd['channelName']):\n",
    "    channel_colors[channel] = colors[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff786f2-85af-4c4e-b331-8d717bb9d2a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Matplotlib Pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3a041-206a-44bd-9377-19aa360763b4",
   "metadata": {},
   "source": [
    "``` python\n",
    "fig = plt.figure(dpi, figsize=(16,20)) # Get a figure object\n",
    "ax1 = fig.add_axes([left, bottom, width height]) #Create a single axis\n",
    "ax2 = -//- # Create multiple axes in the same figure object using fig.\n",
    "    \n",
    "fig, ax = plt.subplot(nrows,ncols,dpi,figsize)# Get axes and figures directly via subplots.\n",
    "ax[index].plot() or ax.plot()\n",
    "ax.set_xticks() # Use indexing if setting it for a specific axes.\n",
    "ax.set_yticks()\n",
    "ax.set_xlim()\n",
    "ax.set_ylim()\n",
    "ax.set_xlabel()\n",
    "ax.set_ylabel()\n",
    "ax.legend(labels)\n",
    "plt.savefig()\n",
    "plt.show() or fig or fig.tight_layout() # To show the figure. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc85a52-3320-4b40-9c8f-49a05e668f95",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Seaborn Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad5fa2-0335-4704-9482-53bd32392009",
   "metadata": {
    "tags": []
   },
   "source": [
    "``` python\n",
    "# Settting basic configurations for the plots.\n",
    "matplotlib.use(\"TkAgg\") #Change the backend of matplotlib, helpful to use GUI plot, default is: 'module://matplotlib_inline.backend_inline'\n",
    "%matplotlib inline # To view plots in nb itself.\n",
    "sns.set(rc={'figure.figsize':(10,8),'figure.dpi':200}) # Set the plot configurations of all params from matplotlib.rc_params(), sns.plotting_context(), sns.axes_style()\n",
    "\n",
    "# Doing the plotting \n",
    "fig,ax = plt.subplots() # use only if more than 1 axes are required, then instead of ax we have to use ax[index] or in sns.plot_type specify the axis to plot the figure on.\n",
    "\n",
    "ax = sns.plot_type(params) #Configuring the plot itself.\n",
    "ax.... # All the variations that require to be done on the axes like ticks formatting, legend formatting etc.\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "#### or\n",
    "``` python\n",
    "rcparams = {'figure.figsize':(13,9), 'axes.titlesize':12, 'axes.labelsize':9, 'xtick.labelsize':9, 'ytick.labelsize':9, 'legend.fontsize':12,'figure.dpi': 200}\n",
    "sns.set(rc=rcparams)\n",
    "#sns.set_palette('husl')\n",
    "\n",
    "education_level = df['parental_level_of_education'].unique()\n",
    "color = sns.color_palette('Set1',len(education_level)) # create a palette with 2 colors (red and blue)\n",
    "hue_colors = {}\n",
    "\n",
    "for i, level in enumerate(education_level): # create a dictionary with the colors for each category\n",
    "    hue_colors[level] = color[i]\n",
    "\n",
    "fig,axs = plt.subplots(1,3,figsize=(25,6))\n",
    "\n",
    "sns.histplot(data=df,x='average',kde=True,hue='parental_level_of_education',ax = axs[0],palette=hue_colors,legend=False)\n",
    "axs[0].set_title('Average distribution of Marks for all students')\n",
    "axs[0].set_xlabel('Average Score')\n",
    "\n",
    "sns.histplot(data=df[df.gender=='male'],x='average',kde=True,hue='parental_level_of_education',ax = axs[1],palette=hue_colors,legend=False)\n",
    "axs[1].set_title('Average distribution of Marks for all male students')\n",
    "axs[1].set_xlabel('Average Score')\n",
    "\n",
    "sns.histplot(data=df[df.gender=='female'],x='average',kde=True,hue='parental_level_of_education',ax = axs[2],palette=hue_colors,legend=False)\n",
    "axs[2].set_title('Average distribution of Marks for all female students')\n",
    "axs[2].set_xlabel('Average Score')\n",
    "\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1,1.15), ncol=2,labels = hue_colors.keys(),title='Parental Education Level')\n",
    "\n",
    "\n",
    "#fig.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a950d-30a4-4e22-9af0-30fd299ee857",
   "metadata": {},
   "source": [
    "- Seaborn\n",
    "``` python\n",
    "tips = sns.load_dataset('name') #Predatasets in sns library itself.\n",
    "```\n",
    "##### Distribution Plots\n",
    "\n",
    "- Distribution Plots\n",
    "    - Distplot shows the distribution of a univariate variable, by combining histograms and kernel density estimate, which is a pdf of the univariate variable.\n",
    "\n",
    "``` python\n",
    "    sns.distplot(data,kde = 'bool', bins, palette)\n",
    "```\n",
    "- Jointplot\n",
    "    - Jointplot allows to create a graph of a bivariate data, where the bivariate plot is in the middle and on the axes we have 2 distplots.\n",
    "\n",
    "``` python\n",
    "sns.jointplot(x,y,data = tips,kind, palette)\n",
    "#x and y can be tips.colname so we can even remove data\n",
    "#kind: scatter, reg, hex, resid, kde \n",
    "```\n",
    "\n",
    "- Pairplot\n",
    "    - Pairplot will plot pairwise relationships across an entire dataframe (for the numerical columns) and supports a color hue argument (for categorical columns).\n",
    "    - Across diagonal you see either histogram or kde, and rest are filled with scatterplots \n",
    "\n",
    "``` python    \n",
    "sns.pairplot(data,hue,palette,diag_kind)\n",
    "```\n",
    "\n",
    "##### Categorical Data Plots\n",
    "\n",
    "- Barplot and countplots\n",
    "    - Barplots find the central tendency for a numeric variable. X here can be just a separation of the numeric variable in categories, like sex.\n",
    "    - Countplot, simply counts the number of occurences for a single variable.\n",
    "``` python\n",
    "sns.barplot(x,y,data) \n",
    "```\n",
    "- Boxplot:\n",
    "    - Shows the 5 point statistics of a numericvariable divided by categories.\n",
    "``` python    \n",
    "sns.boxplot(x,y,data,palette,orient,hue)\n",
    "```\n",
    "\n",
    "##### Matrix Plots\n",
    "- Matrix plots allow you to plot data as color-encoded matrices and can also be used to indicate clusters within the data (later in the machine learning section we will learn how to formally cluster data).\n",
    "\n",
    "``` python\n",
    "sns.heatmaps(pvtdata or corr data, cmap = 'coolwarm')\n",
    "```\n",
    "\n",
    "##### Regression Plots\n",
    "- Simple regression plots to predict a target variable by another feature variable.\n",
    "``` python\n",
    "sns.lmplot(x='total_bill',y='tip',data=tips,col='day',row='smoker',hue='sex', palette='coolwarm', aspect=1.5,size=8)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ae40f-7773-4167-8e76-f9d92891ac11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c499c-8cfa-4d03-803f-56b9c0ccb9da",
   "metadata": {},
   "source": [
    "- Airflow's extensible Python framework enables you to build workflows connecting with virtually any technology. \n",
    "- A web interface helps manage the state of your workflows. \n",
    "- Airflow is deployable in many ways, varying from a single process on your laptop to a distributed setup to support even the biggest workflows.\n",
    "- Dynamic: Airflow pipelines are configured as Python code, allowing for dynamic pipeline generation.\n",
    "- Extensible: The Airflow framework contains operators to connect with numerous technologies. \n",
    "- All Airflow components are extensible to easily adjust to your environment.\n",
    "- Flexible: Workflow parameterization is built-in leveraging the Jinja templating engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c92d1c-d97c-490c-90fb-39ca6821eaeb",
   "metadata": {},
   "source": [
    "## Jupyter lab n Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842909c2-b43f-416a-94ca-7281942e899c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Installing jupyter bit n bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea8530-c42a-4607-9ce7-e3e55c5a5e84",
   "metadata": {},
   "source": [
    "- Tips \n",
    "    - Use conda to manage envs\n",
    "    - Use pip mostly to install packages\n",
    "- Selective conda installs\n",
    "    - nodejs\n",
    "``` bash\n",
    "    conda install nodejs\n",
    "    conda upgrade -c conda-forge nodejs #To upgrade to latest version supported by jupyter lab extensions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b36a1-186d-40d1-acca-db89eda204ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pandas & Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7450212-0e4a-49de-a951-cb704f3625a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Reading a df and manipulation a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc9837-81d1-4258-9a93-38b67a30358c",
   "metadata": {},
   "source": [
    "- Reading a dataframe\n",
    "```Python\n",
    "df = pd.read_csv(\"data.csv\",index = False)\n",
    "```\n",
    "\n",
    "- Renaming columns\n",
    "```Python\n",
    "df = df.rename(columns = {'old_name':'new_name','old_name2':'new_name2','old_name3':'new_name3'})\n",
    "```\n",
    "\n",
    "- Reset the index of pandas\n",
    "```Python\n",
    "df = df.reset_index()\n",
    "```\n",
    "\n",
    "- Setting up column dtypes manually\n",
    "```Python\n",
    "df = pd.read_csv('abc.csv',parse_date = ['Date'])\n",
    "df.info()\n",
    "\n",
    "# or\n",
    "df = pd.read_csv('abc.csv',index = False)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.info\n",
    "\n",
    "```\n",
    "\n",
    "- Use string methods\n",
    "``` python\n",
    "# use\n",
    "df['Name_Uppercase'] = df['Name'].str.upper()\n",
    "\n",
    "\n",
    "# instead of\n",
    "df['Name_Uppercase'] = df['Name'].apply(lambda x: str(x).upper())\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b463c4-e234-484a-981d-02f2148b5c13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c4725-1395-433a-9d89-90707674176a",
   "metadata": {},
   "source": [
    "- Check null and Dtypes\n",
    "``` python\n",
    "df.info()\n",
    "```\n",
    "\n",
    "- Check the number of unique values of each column\n",
    "``` python\n",
    "df.nunique()\n",
    "```\n",
    "\n",
    "- Check statistics of the data\n",
    "```Python\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "- Indexing the columns\n",
    "``` python\n",
    "df.loc[r1_name:r10_name,c1_name:c5_name]\n",
    "# The last index is used in loc.\n",
    "\n",
    "# or\n",
    "df.iloc[1:10m,1:5]\n",
    "# The last index is not used in iloc\n",
    "\n",
    "# reverse the rows\n",
    "df.loc[::-1].head()\n",
    "\n",
    "# reverse the columns \n",
    "df.loc[:,::-1].head()\n",
    "```\n",
    "\n",
    "- Seperating numerical and categorical columns\n",
    "``` python\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a65bfc-15d4-44c7-9828-317cc711a0ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conditional filtering and Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32a4cf-5c95-4af5-bff3-cdc9fb0fdba8",
   "metadata": {},
   "source": [
    "- Counting\n",
    "```python\n",
    "# Find the count by a categorical attribute\n",
    "df.col_name.value_counts()\n",
    "```\n",
    "\n",
    "- Duplicate count\n",
    "``` python\n",
    "df.duplicated().sum()\n",
    "```\n",
    "\n",
    "- Conditional filtering and Querying\n",
    "```python\n",
    "df[( df[\"Embarked\"] == 'S') & (df[\"Sex\"] == 'female') & (df[\"Survived\"] == 1) ].head()\n",
    "```\n",
    "\n",
    "- Querying the columns\n",
    "```Python\n",
    "min_year = 1980\n",
    "min_time = 10\n",
    "df = df.query(\"Year < @min_year and Time > @min_time\")\n",
    "df\n",
    "```\n",
    "\n",
    "- Iterating over the rows of dataframe via broadcasting, i.e. vectorized function\n",
    "```Python\n",
    "df['result'] = df['Year'] > 1980\n",
    "df\n",
    "```\n",
    "\n",
    "- Instead of apply method use the vectorized version if possible.\n",
    "```Python\n",
    "# Use\n",
    "df['year_square'] = df['year'] ** 2\n",
    "df.head()\n",
    "# Instead of \n",
    "df['year_square'] = df.apply(lambda row: row[\"year\"]**2, axis = 1)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69875c89-cbf8-40c9-820a-b927509806f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NA Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f25fa9-f3a5-454a-965b-31d00840a430",
   "metadata": {},
   "source": [
    "- Fill na, and never use inplace as it's not a good method.\n",
    "```Python\n",
    "df = df.fillna(0)\n",
    "```\n",
    "\n",
    "- Calculate Null Values\n",
    "``` python\n",
    "df.isna().sum()\n",
    "```\n",
    "\n",
    "- Dropping Null Columns\n",
    "``` python\n",
    "df.dropna( axis='index').info() #Index axis is x axis we can use 0 as well, and columns as axis is same as using 1\n",
    "```\n",
    "\n",
    "- Fill with some values \n",
    "```python\n",
    "df[\"Cabin\"].fillna(\"Default Cabin\" , inplace = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7a7ab-a709-468b-a9a6-25bb41304edc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Noob mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09af29-c9da-4eec-b873-7e4d89b28db7",
   "metadata": {},
   "source": [
    "- Create a copy of df, so that it doesn't effect the original, especially for the slice of df\n",
    "```Python\n",
    "df_fast = df.query('Time < 10').copy() # A Slice of DS\n",
    "df_fast['country'] = df_fast['Name'].str[-5:]\n",
    "df_fast\n",
    "```\n",
    "\n",
    "- Use chaining commands to apply all changes to df at once.\n",
    "```Python\n",
    "# Use\n",
    "df_out = (df.query('Year > 1975')\n",
    "          .groupby(['Athlete'])[['Time']].min()\n",
    "          .sort_values('Athlete')\n",
    "         )\n",
    "df_out\n",
    "\n",
    "# Instead of \n",
    "df2 = df.query('Year > 1975')\n",
    "df3 = df2.groupby(['Athlete'])[['Time']].min()\n",
    "df_out = df3.sort_values('Athlete')\n",
    "df_out\n",
    "```\n",
    "- Use inbuilt pandas plotting functionality\n",
    "```Python\n",
    "ax = df.plot(kind = 'scatter',\n",
    "            x = 'Year',\n",
    "            y = 'Time',\n",
    "            title = 'Year vs Speed'\n",
    "            )\n",
    "```\n",
    "- Create functions to process data instead of processing them manually each time.\n",
    "``` python\n",
    "def process_data(df):\n",
    "    df['Time_Norm'] = df['Time']/df['Time'].mean()\n",
    "    df['Place'] = df['Place'].str.lower()\n",
    "    return df\n",
    "\n",
    "dfm = process_data(dfm)\n",
    "dfw = process_data(dfw)\n",
    "dfw\n",
    "```\n",
    "\n",
    "- Grouping of data\n",
    "``` python\n",
    "df.groupby('Grouping')['Time'].min()\n",
    "\n",
    "# Looping over the data of the dataframe\n",
    "df.groupby('Grouping')['Time'].agg(['mean','count'])\n",
    "```\n",
    "\n",
    "- Saveing large data\n",
    "``` python\n",
    "# use\n",
    "large_df.to_parquet('op.parquet')\n",
    "large_df.to_feather('op.feather')\n",
    "large_df.to_pickle('op.pickle')\n",
    "# instead of \n",
    "large_df.to_csv(\"abc.csv\")\n",
    "```\n",
    "\n",
    "- Conditional formatting in pandas with html styling\n",
    "``` python\n",
    "df.sort_values( 'Time' ).head(10)[['Name','Time']] \\\n",
    ".reset_index(drop=True) \\\n",
    ".style \\\n",
    ".background gradient(cmap=\"Reds\")\n",
    "```\n",
    "\n",
    "- Giving suffixes while merging 2 df's with validation\n",
    "``` python\n",
    "df1 = pd.read_csv( 'mens100m.csv' )\n",
    "df2  = pd.read_csv( 'womens100m.csv' )\n",
    "df_merged = df1.merge(df2,on=['Year'],suffixes = ('_mens','_womens'),validate = 'm:1')\n",
    "\n",
    "#  validate options:\n",
    "# \"one to one\" or \"1: 1\": check if merge keys are unique in both datasets.\n",
    "# \"one to many\" or \"l:m\": check if merge keys are unique in left dataset.\n",
    "#\"many to one\" or \"m: 1\": check if merge keys are unique in right dataset.\n",
    "# \"many to many\" or \"m:m\": allowed, but does not result in checks.\n",
    "```\n",
    "\n",
    "- Wrapping the chaining components well, for readability\n",
    "``` python\n",
    "df_agg = (\n",
    "    df\n",
    "    .groupby(['Grouping','Year'])['Time']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .fillna(0)\n",
    "    .sort_values(\"Year\")\n",
    "    \n",
    ")\n",
    "df_agg\n",
    "```\n",
    "\n",
    "- Making columns categorical which has categorical data for speeding up the process\n",
    "``` python\n",
    "df['Grouping'] = df['Grouping'].astype('category')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba7930-ce57-4634-8a37-494d959fbc80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
